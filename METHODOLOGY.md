# Methodology: Department-Specific Language Generation

## Purpose of This Document

This document provides transparency about how the department-specific language in the AI Syllabus Statement Builder was created. Faculty using this tool deserve to know the provenance and limitations of the suggested text.

## Summary

The 40 department-specific templates were **generated through AI synthesis of disciplinary discourse patterns**, not through empirical research, faculty interviews, or validated pedagogical studies. This language serves as a **starting point for faculty review and adaptation**, not as research-backed best practices.

---

## Generation Process

### Step 1: Identify Core Pedagogical Question
For each department, we asked:
> "What's the irreplaceable cognitive, physical, or embodied practice that students must do themselves in this field?"

Examples:
- **Computer Science**: Algorithmic thinking through debugging and problem decomposition
- **English**: Close reading and developing analytical voice through writing
- **Chemistry**: Laboratory technique and chemical intuition through hands-on work
- **Philosophy**: Logical reasoning through wrestling with conceptual problems
- **WGSS**: Intersectional analysis of power through engagement with feminist/queer theory

### Step 2: Understand Disciplinary Epistemology
We analyzed how each field produces knowledge:
- **STEM**: Verification, testing, problem-solving from first principles
- **Humanities**: Interpretation, textual evidence, close reading, voice
- **Social Sciences**: Methodology, research ethics, evidence evaluation
- **Natural Sciences**: Observation, experimental design, troubleshooting
- **Languages**: Fluency, production (not just translation), thinking in target language
- **Creative Fields**: Technical skill, aesthetic judgment, intentional choices
- **Area Studies**: Language proficiency + critical frameworks (decolonial theory, Orientalism)

### Step 3: Generate Considerations Questions
Five questions per department designed to surface:
- Skills that require sustained practice
- Where AI creates pedagogical risk
- Field-specific methods and values
- Professional practice contexts

Questions were tailored to disciplinary concerns (e.g., "Can students trace code execution without AI assistance?" for CS vs. "Can they read unvocalized texts with comprehension?" for Arabic).

### Step 4: Create Policy Rationales with Consistent Pattern

**Structure used across all 40 departments:**

**noAI**: "AI cannot develop your ability to [core skill]. These capacities emerge from [what practice provides]."
- Focus: What's cognitively/physically irreplaceable

**limited**: "You may use AI for [peripheral tasks] after [foundational work], but [core work] must be yours."
- Focus: Boundaries between appropriate and inappropriate AI use

**ok**: "You remain responsible for [quality markers]. AI can [assist], but [professional judgment] is yours."
- Focus: Student accountability despite AI availability

**required**: "Understanding [AI's role in field] prepares you for [professional reality] where [how field is changing]."
- Focus: AI literacy as professional preparation

### Step 5: Use Disciplinary Vocabulary
Language employs field-specific terminology drawn from how academics typically describe their disciplines:
- **Computer Science**: "algorithmic thinking," "problem decomposition," "edge cases"
- **Philosophy**: "dialectical engagement," "conceptual problems," "logical validity"
- **WGSS**: "intersectionality," "patriarchy," "heteronormativity"
- **Classics**: "parsing," "grammatical analysis," "ancient Mediterranean contexts"

### Step 6: Emphasize Critical Frameworks (Identity-Based Fields)
For Africana Studies, WGSS, area studies programs, language emphasizes:
- Representation and whose perspectives are centered
- Power relations in knowledge production
- Biases in AI training data
- Relevant theoretical frameworks (Orientalism, intersectionality, decolonial thought)
- Respectful engagement with communities and traditions

---

## What This Approach Provides

✅ **Consistent structure** across all departments (same rhetorical pattern)
✅ **Field-specific content** tailored to disciplinary methods and values
✅ **Pedagogically plausible** language grounded in how fields describe themselves
✅ **Starting point** for faculty to edit and validate for their courses

---

## What This Approach Does NOT Provide

❌ **Empirical research** about what faculty actually need
❌ **Validation** by experts in these 40 fields
❌ **Learning science evidence** about what AI policies "work" (though guidance about *explaining* policy rationale is informed by motivation and academic integrity research—see References section below)
❌ **Professional association endorsement** (ACM, MLA, AHA, etc.)
❌ **Student testing** or outcomes data
❌ **Institutional context** specific to your university
❌ **Course-specific nuance** for your particular class

---

## Sources and Synthesis

The AI language generation drew on:
- Academic discourse about disciplinary thinking and methods
- How scholars describe their fields in syllabi, course descriptions, and program materials
- Professional practices in different fields
- Existing conversations about AI in higher education
- Patterns in how disciplines conceptualize skill development

**What was NOT used:**
- Interviews with faculty
- Empirical studies of AI pedagogy by field
- Field-specific research on learning outcomes
- Systematic review of professional association statements
- Analysis of actual syllabi with AI policies

## Research Informing Tool Guidance

While the discipline-specific content was generated through AI synthesis (see above), some **guidance about policy communication** is informed by educational research:

### Why Explain Policy Rationale to Students

**Self-Determination Theory Research:**
- Wang et al. (2024) meta-analysis found that teacher autonomy support—including providing explanatory rationales for rules—strongly predicts students' need satisfaction and self-determined motivation
- Niemiec & Ryan (2009) identified that providing rationales for policies supports students' internalization of why the work matters

**Academic Integrity Research:**
- Miller et al. (2023) literature review found that students often commit academic misconduct because they don't understand rules and expectations, or don't see the value in honest learning
- Research emphasizes that intentionally aligning assignments to learning outcomes and clearly communicating that alignment to students is a key strategy for reducing misconduct
- Positive framing about why integrity matters is more effective than emphasizing fear or punishment

### References

- **Miller, A. D., Griffiths, Z., Lockyer, L., & Mah, D. K. (2023).** Why students cheat and how understanding this can help reduce the frequency of academic misconduct in higher education: A literature review. *Journal of University Teaching & Learning Practice, 20*(6). https://pmc.ncbi.nlm.nih.gov/articles/PMC10653228/

- **Niemiec, C. P., & Ryan, R. M. (2009).** Autonomy, competence, and relatedness in the classroom: Applying self-determination theory to educational practice. *Theory and Research in Education, 7*(2), 133-144. https://journals.sagepub.com/doi/10.1177/1477878509104318

- **Ohio State University Center for Teaching and Learning.** A positive approach to academic integrity. https://teaching.resources.osu.edu/teaching-topics/positive-approach-academic

- **Wang, L., Liu, Q., Du, X., & Liu, J. (2024).** Pathways to student motivation: A meta-analysis of antecedents of autonomous and controlled motivations. *Learning and Motivation, 87*, 102015. https://selfdeterminationtheory.org/wp-content/uploads/2024/06/2024_WangWangEtAl_MetaEdu.pdf

---

## Recommended Faculty Workflow

1. **Select your department** to see tailored starting language
2. **Review considerations questions** to reflect on your course goals
3. **Read suggested text** with critical eye toward your context
4. **Edit extensively** to match your course, students, and teaching philosophy
5. **Consult colleagues** in your department about disciplinary norms
6. **Check professional associations** (ACM, MLA, AHA, etc.) for research-backed guidance
7. **Review existing policies** via [Lance Eaton's AI Policy Database](https://docs.google.com/spreadsheets/d/1-R8wxAB6V11cDh_u6t-WgCBdxYKV8FoXDFGxPVxbs6k/)
8. **Align with institutional policies** on academic integrity
9. **Test with students** and revise based on questions/confusion
10. **Iterate** - AI policies are living documents as technology evolves

---

## Accountability Statement

We believe faculty deserve to know:
- **How this language was created** (AI synthesis, not research)
- **What it can and cannot do** (starting point, not validated practice)
- **Where to find better sources** (professional associations, colleagues, research)

This tool aims to **reduce friction** in creating AI policies, not to replace **faculty expertise and judgment** about teaching in their disciplines.

---

## Questions or Concerns?

If you have questions about this methodology or suggestions for improving the tool's transparency:
- Submit feedback via the tool's feedback link
- Consult your institution's teaching center
- Share concerns with the PLAI Lab at Washington & Lee University

---

**Document Version**: 1.0
**Last Updated**: January 2025
**Tool Version**: 2.0 (40 departments, progressive disclosure pattern)
